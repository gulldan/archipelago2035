#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ì–æ—Ç–æ–≤–∏—Ç YOLO-–¥–∞—Ç–∞—Å–µ—Ç (train/val) –∏–∑ –ø–∞–ø–æ–∫ Rescue-SAR, –∞–∫–∫—É—Ä–∞—Ç–Ω–æ:
- –ù–ò–ß–ï–ì–û –Ω–µ –ø–∏—à–µ—Ç –≤ source;
- –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–ª–∏—Ç –ø–æ –Ω–∞–ª–∏—á–∏—é –æ–±—ä–µ–∫—Ç–æ–≤ (pos/neg);
- –ß–∏–Ω–∏—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ (–∫–ª–∞–º–ø [0,1], –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫–∏, –∫–ª–∞—Å—Å -> 0);
- –ü–∏—à–µ—Ç mapping.csv –∏ dataset.yaml.
"""

from __future__ import annotations

import csv
import random
import shutil
from dataclasses import dataclass
from pathlib import Path
from typing import List, Optional, Tuple

from tqdm import tqdm

# ---- –ù–ê–°–¢–†–û–ô–ö–ò ----
DATASET_FOLDERS = [
    "01_train-s1__DataSet_Human_Rescue",
    "02_second_part_DataSet_Human_Rescue",
    "04_ladd",
    "05_pd",
]
IMAGE_EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".tif", ".tiff"}
LABEL_EXT = ".txt"

VAL_FRACTION = 0.20  # –¥–æ–ª—è –∫–∞—Ä—Ç–∏–Ω–æ–∫ –≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
RANDOM_SEED = 42
SPLIT_BY_SCENE = (
    False  # –µ—Å–ª–∏ True ‚Äî –≤–∞–ª–∏–¥ —Ä–∞–∑–º–µ—á–∞–µ—Ç—Å—è –ø–æ –≤–µ—Ä—Ö–Ω–∏–º –ø–∞–ø–∫–∞–º (–º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ—Ç ¬´—Å–ª–∏–≤¬ª —Å—Ü–µ–Ω)
)
ENSURE_MIN_VAL_POS = 50  # –º–∏–Ω–∏–º—É–º –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –∫–∞—Ä—Ç–∏–Ω–æ–∫ –≤ val (–µ—Å–ª–∏ —Ö–≤–∞—Ç–∞–µ—Ç)

# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –±–æ–∫—Å–æ–≤ –Ω–∞ —ç—Ç–∞–ø–µ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ (–±–µ—Ä–µ–∂–Ω–∞—è)
CLAMP_TO_UNIT = True  # –∫–ª–∞–º–ø–∏–º xywhn –≤ [0,1]
DROP_TINY_WH = 1e-6  # –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º –±–æ–∫—Å—ã —Å w/h <= —ç—Ç–æ–≥–æ –ø–æ—Ä–æ–≥–∞ (–Ω–æ—Ä–º.)
FORCE_CLASS_ZERO = True  # –≤—Å–µ –∫–ª–∞—Å—Å—ã -> 0 (—É –Ω–∞—Å 1 –∫–ª–∞—Å—Å person)

# -------------------


@dataclass
class Item:
    img: Path
    lbl: Optional[Path]  # –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å
    has_pos: bool  # –µ—Å—Ç—å –≤–∞–ª–∏–¥–Ω—ã–µ –±–æ–∫—Å—ã
    src_folder: str  # –≤–µ—Ä—Ö–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å (–¥–ª—è group split)


def find_image_files(root: Path) -> List[Path]:
    return [
        p for p in root.rglob("*") if p.suffix.lower() in IMAGE_EXTS and p.is_file()
    ]


def guess_label_path(img_path: Path) -> Path:
    """
    –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ txt-–ª–µ–π–±–ª –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–∫–∏:
    - .../images/xxx.jpg -> .../labels/xxx.txt
    - –∏–ª–∏ —Ä—è–¥–æ–º (xxx.txt –≤ —Ç–æ–π –∂–µ –ø–∞–ø–∫–µ)
    """
    # 1) –µ—Å–ª–∏ –≤–Ω—É—Ç—Ä–∏ .../images/... -> –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ .../labels/...
    parts = list(img_path.parts)
    if "images" in parts:
        i = parts.index("images")
        parts[i] = "labels"
        cand = Path(*parts).with_suffix(LABEL_EXT)
        if cand.exists():
            return cand
    # 2) —Ç–æ—Ç –∂–µ –∫–∞—Ç–∞–ª–æ–≥
    cand2 = img_path.with_suffix(LABEL_EXT)
    if cand2.exists():
        return cand2
    # 3) —Å–æ—Å–µ–¥–Ω—è—è –ø–∞–ø–∫–∞ labels –Ω–∞ —Ç–æ–º –∂–µ —É—Ä–æ–≤–Ω–µ
    if "images" in parts:
        i = parts.index("images")
        alt = Path(*parts[:i], "labels", *parts[i + 1 :]).with_suffix(LABEL_EXT)
        if alt.exists():
            return alt
    return Path()  # –ø—É—Å—Ç–æ–π -> –Ω–µ—Ç


def read_and_fix_labels(
    lbl_path: Path,
) -> List[Tuple[float, float, float, float, float]]:
    """
    –°—á–∏—Ç—ã–≤–∞–µ–º YOLO-—Ä–∞–∑–º–µ—Ç–∫—É (class xc yc w h) –∏ —á–∏–Ω–∏–º:
    - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –±–∏—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏;
    - –∫–ª–∞—Å—Å -> 0 (–µ—Å–ª–∏ FORCE_CLASS_ZERO);
    - –∫–ª–∞–º–ø–∏–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ [0,1];
    - –≤—ã–∫–∏–¥—ã–≤–∞–µ–º –Ω—É–ª–µ–≤—ã–µ/–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –±–æ–∫—Å—ã.
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤–∞–ª–∏–¥–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π.
    """
    if not lbl_path.exists() or lbl_path.stat().st_size == 0:
        return []

    valid = []
    with open(lbl_path, "r", encoding="utf-8", errors="ignore") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            parts = line.split()
            if len(parts) < 5:
                continue
            try:
                c = float(parts[0])
                xc = float(parts[1])
                yc = float(parts[2])
                w = float(parts[3])
                h = float(parts[4])
            except ValueError:
                continue

            if FORCE_CLASS_ZERO:
                c = 0.0

            if CLAMP_TO_UNIT:
                # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ xyxy, –∫–ª–∞–º–ø–∏–º, –æ–±—Ä–∞—Ç–Ω–æ –≤ xywh
                x1 = max(0.0, min(1.0, xc - w / 2))
                y1 = max(0.0, min(1.0, yc - h / 2))
                x2 = max(0.0, min(1.0, xc + w / 2))
                y2 = max(0.0, min(1.0, yc + h / 2))
                w = max(0.0, x2 - x1)
                h = max(0.0, y2 - y1)
                if w <= DROP_TINY_WH or h <= DROP_TINY_WH:
                    continue
                xc = x1 + w / 2
                yc = y1 + h / 2
            else:
                if w <= DROP_TINY_WH or h <= DROP_TINY_WH:
                    continue

            valid.append((c, xc, yc, w, h))

    return valid


def collect_items(source_dir: str) -> List[Item]:
    src = Path(source_dir)
    items: List[Item] = []

    for folder in DATASET_FOLDERS:
        folder_path = src / folder
        if not folder_path.exists():
            print(f"‚ö†Ô∏è  –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {folder_path}")
            continue
        top_name = folder_path.name

        print(f"üìÅ –°–∫–∞–Ω–∏—Ä—É–µ–º {folder_path}")
        for img in tqdm(
            find_image_files(folder_path), desc=f"  ‚ûú images in {top_name}"
        ):
            lbl = guess_label_path(img)
            labels = read_and_fix_labels(lbl) if lbl and lbl.exists() else []
            items.append(
                Item(
                    img=img,
                    lbl=(lbl if lbl.exists() else None),
                    has_pos=(len(labels) > 0),
                    src_folder=top_name,
                )
            )
    return items


def stratified_split(
    items: List[Item],
    val_fraction: float,
    seed: int,
    split_by_scene: bool = False,
    ensure_min_val_pos: int = 0,
):
    """
    –î–µ–ª–∏–º –Ω–∞ train/val:
    - —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ has_pos (–ø–æ–∑–∏—Ç–∏–≤/–Ω–µ–≥–∞—Ç–∏–≤),
    - –æ–ø—Ü–∏—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ –≤–µ—Ä—Ö–Ω–µ–π –ø–∞–ø–∫–µ (–º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ—Ç —É—Ç–µ—á–∫—É –ø–æ—Ö–æ–∂–∏—Ö —Å—Ü–µ–Ω).
    """
    rng = random.Random(seed)

    if split_by_scene:
        # –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø–∞–ø–∫–∞–º; –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–π ‚Äî —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ
        train, val = [], []
        folders = {}
        for it in items:
            folders.setdefault(it.src_folder, []).append(it)
        for _, group in folders.items():
            pos = [it for it in group if it.has_pos]
            neg = [it for it in group if not it.has_pos]
            rng.shuffle(pos)
            rng.shuffle(neg)
            vp = int(round(len(pos) * val_fraction))
            vn = int(round(len(neg) * val_fraction))
            val.extend(pos[:vp] + neg[:vn])
            train.extend(pos[vp:] + neg[vn:])
    else:
        pos = [it for it in items if it.has_pos]
        neg = [it for it in items if not it.has_pos]
        rng.shuffle(pos)
        rng.shuffle(neg)
        vp = int(round(len(pos) * val_fraction))
        vn = int(round(len(neg) * val_fraction))

        # –≥–∞—Ä–∞–Ω—Ç –º–∏–Ω–∏–º—É–º –ø–æ–∑–∏—Ç–∏–≤–æ–≤ –≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏, –µ—Å–ª–∏ —Ö–≤–∞—Ç–∞–µ—Ç
        if ensure_min_val_pos and len(pos) >= ensure_min_val_pos:
            vp = max(vp, ensure_min_val_pos)

        val = pos[:vp] + neg[:vn]
        train = pos[vp:] + neg[vn:]

    rng.shuffle(train)
    rng.shuffle(val)
    return train, val


def write_dataset(
    items: List[Item],
    out_split_dir: Path,
    new_prefix: str,
    mapping_writer: csv.writer,
):
    """
    –ö–æ–ø–∏—Ä—É–µ–º/–ø–∏—à–µ–º –ª–µ–π–±–ª—ã –≤ out_split_dir/images|labels —Å –Ω–æ–≤—ã–º–∏ –∏–º–µ–Ω–∞–º–∏.
    –ï—Å–ª–∏ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ label –Ω–µ—Ç ‚Äî —Å–æ–∑–¥–∞—ë–º –ø—É—Å—Ç–æ–π.
    –ï—Å–ª–∏ label –µ—Å—Ç—å ‚Äî –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–µ–º –ß–ò–ù–ï–ù–ù–´–ï —Å—Ç—Ä–æ–∫–∏.
    """
    (out_split_dir / "images").mkdir(parents=True, exist_ok=True)
    (out_split_dir / "labels").mkdir(parents=True, exist_ok=True)

    for i, it in enumerate(tqdm(items, desc=f"–ö–æ–ø–∏—Ä—É–µ–º {out_split_dir.name}")):
        stem = f"{new_prefix}_{i:06d}"
        img_dst = out_split_dir / "images" / f"{stem}{it.img.suffix.lower()}"
        lbl_dst = out_split_dir / "labels" / f"{stem}{LABEL_EXT}"

        shutil.copy2(it.img, img_dst)

        if it.lbl and it.lbl.exists():
            fixed = read_and_fix_labels(it.lbl)
            if fixed:
                with open(lbl_dst, "w", encoding="utf-8") as fw:
                    for c, xc, yc, w, h in fixed:
                        fw.write(f"{int(c)} {xc:.6f} {yc:.6f} {w:.6f} {h:.6f}\n")
            else:
                lbl_dst.touch()
        else:
            lbl_dst.touch()

        mapping_writer.writerow(
            [str(it.img), str(it.lbl) if it.lbl else "", str(img_dst), str(lbl_dst)]
        )


def prepare_yolo_dataset(
    source_dir: str = "./dataset",
    output_dir: str = "./dataset/yolo_dataset",
    val_fraction: float = VAL_FRACTION,
    seed: int = RANDOM_SEED,
    split_by_scene: bool = SPLIT_BY_SCENE,
) -> bool:
    random.seed(seed)

    src = Path(source_dir)
    out = Path(output_dir)
    if out.exists():
        shutil.rmtree(out)

    items = collect_items(source_dir)
    if not items:
        print("‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã ‚Äî –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç–∏ –≤ DATASET_FOLDERS")
        return False

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–æ —Å–ø–ª–∏—Ç–∞
    n_total = len(items)
    n_pos = sum(1 for it in items if it.has_pos)
    n_neg = n_total - n_pos
    print(
        f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {n_total}  |  c –æ–±—ä–µ–∫—Ç–∞–º–∏: {n_pos}  |  –ø—É—Å—Ç—ã—Ö: {n_neg}"
    )

    train, val = stratified_split(
        items,
        val_fraction,
        seed,
        split_by_scene=split_by_scene,
        ensure_min_val_pos=ENSURE_MIN_VAL_POS,
    )
    print(f"‚Üí Train: {len(train)}  |  Val: {len(val)}")

    # –ü–∏—à–µ–º mapping.csv
    (out).mkdir(parents=True, exist_ok=True)
    with open(out / "mapping.csv", "w", newline="", encoding="utf-8") as fmap:
        mw = csv.writer(fmap)
        mw.writerow(["src_image", "src_label", "dst_image", "dst_label"])
        write_dataset(train, out / "train", "train", mw)
        write_dataset(val, out / "val", "val", mw)

    # dataset.yaml
    yaml_text = f"""# Rescue-SAR YOLO dataset (auto-generated, v2)
path: {out.resolve()}
train: train/images
val: val/images

nc: 1
names: ['person']

# stats
train_images: {len(train)}
val_images: {len(val)}
total_images: {n_total}
pos_images: {n_pos}
neg_images: {n_neg}
"""
    (out / "dataset.yaml").write_text(yaml_text, encoding="utf-8")
    print(f"üìã dataset.yaml —Å–æ–∑–¥–∞–Ω: {out / 'dataset.yaml'}")
    print(f"üß≠ mapping.csv: {out / 'mapping.csv'}")

    return True


if __name__ == "__main__":
    ok = prepare_yolo_dataset()
    print("\nüéâ –î–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã!" if ok else "\n‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
